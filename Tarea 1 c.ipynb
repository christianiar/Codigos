{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "Imports"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4],\n",
       "       [4],\n",
       "       ...,\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_test = sio.loadmat(\"AgeGenderClassification\\eventest.mat\")\n",
    "mat_train = sio.loadmat(\"AgeGenderClassification\\eventrain.mat\")\n",
    "data_train= mat_train[\"trcoll\"][0][0]\n",
    "data_test= mat_test[\"tecoll\"][0][0]\n",
    "\n",
    "#HotVector\n",
    "g = 0\n",
    "\n",
    "while g<(len(data_train[1])-1):\n",
    "    \n",
    "    if data_train[1][g] == 1:\n",
    "        data_train[1][g] = 0\n",
    "    \n",
    "    if data_train[1][g] == 5:\n",
    "        data_train[1][g] = 1\n",
    "    \n",
    "    if data_train[1][g] == 10:\n",
    "        data_train[1][g] = 2\n",
    "    \n",
    "    if data_train[1][g] == 16:\n",
    "        data_train[1][g] = 3\n",
    "        \n",
    "    if data_train[1][g] == 28:\n",
    "        data_train[1][g] = 4\n",
    "    \n",
    "    if data_train[1][g] == 51:\n",
    "        data_train[1][g] = 5\n",
    "        \n",
    "    if data_train[1][g] == 75:\n",
    "        data_train[1][g] = 6\n",
    "    \n",
    "    g = g + 1\n",
    "    \n",
    "f = 0\n",
    "    \n",
    "while f<(len(data_test[1])):\n",
    "    \n",
    "    if data_test[1][f] == 1:\n",
    "        data_test[1][f] = 0\n",
    "    \n",
    "    if data_test[1][f] == 5:\n",
    "        data_test[1][f] = 1\n",
    "    \n",
    "    if data_test[1][f] == 10:\n",
    "        data_test[1][f] = 2\n",
    "    \n",
    "    if data_test[1][f] == 16:\n",
    "        data_test[1][f] = 3\n",
    "        \n",
    "    if data_test[1][f] == 28:\n",
    "        data_test[1][f] = 4\n",
    "    \n",
    "    if data_test[1][f] == 51:\n",
    "        data_test[1][f] = 5\n",
    "        \n",
    "    if data_test[1][f] == 75:\n",
    "        data_test[1][f] = 6\n",
    "    \n",
    "    f = f + 1\n",
    "    \n",
    "data_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[1] = keras.utils.to_categorical(data_train[1],num_classes=7)\n",
    "data_test[1] = keras.utils.to_categorical(data_test[1],num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 600)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0] = pd.DataFrame(data_train[0]) \n",
    "data_train[0].shape\n",
    "total_0 = len(data_train[0])\n",
    "data_train_0 = data_train[0][:int(0.7*total_0)]\n",
    "data_val_0 = data_train[0][int(0.7*total_0)::]\n",
    "\n",
    "data_train[1] = pd.DataFrame(data_train[1]) \n",
    "data_train[1].shape\n",
    "total_1 = len(data_train[1])\n",
    "data_train_1 = data_train[1][:int(0.7*total_1)]\n",
    "data_val_1 = data_train[1][int(0.7*total_1)::]\n",
    "\n",
    "data_train[3] = pd.DataFrame(data_train[3]) \n",
    "data_train[3].shape\n",
    "total_3 = len(data_train[3])\n",
    "data_train_3 = data_train[3][:int(0.7*total_3)]\n",
    "data_val_3 = data_train[3][int(0.7*total_3)::]\n",
    "\n",
    "data_train[4] = pd.DataFrame(data_train[4]) \n",
    "data_train[4].shape\n",
    "total_4 = len(data_train[4])\n",
    "data_train_4 = data_train[4][:int(0.7*total_4)]\n",
    "data_val_4 = data_train[4][int(0.7*total_4)::]\n",
    "\n",
    "\n",
    "data_test[0] = pd.DataFrame(data_test[0]) \n",
    "data_test[0].shape\n",
    "\n",
    "data_test[1] = pd.DataFrame(data_test[1]) \n",
    "data_test[1].shape\n",
    "\n",
    "data_test[3] = pd.DataFrame(data_test[3]) \n",
    "data_test[3].shape\n",
    "\n",
    "data_test[4] = pd.DataFrame(data_test[4]) \n",
    "data_test[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datos train =  59507000 \n",
      "Total datos test =  7562100\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "total_datos_train = 0\n",
    "total_datos_test = 0\n",
    "input_dim_size = [None]*11\n",
    "while n<11:\n",
    "    numrows = len(data_train[n])\n",
    "    numcols = len(data_train[n][0])\n",
    "    #print(\"Datos[\",n,\"] = \",numrows, numcols)\n",
    "    input_dim_size[n] = numcols*numrows\n",
    "    total_datos_train = (numrows*numcols)+total_datos_train\n",
    "    numrowste = len(data_test[n])\n",
    "    numcolste = len(data_test[n][0])\n",
    "    #print(\"Datos[\",n,\"] = \",numrowste, numcolste)\n",
    "    total_datos_test = (numrowste*numcolste)+total_datos_test\n",
    "    n = n + 1\n",
    "print(\"Total datos train = \",total_datos_train,\"\\nTotal datos test = \",total_datos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2450, 14) (2450, 7) (2450, 37) (2450, 600)\n"
     ]
    }
   ],
   "source": [
    "print(data_train_0.shape,data_train_1.shape,data_train_3.shape,data_train_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_total = np.concatenate((data_train_0, data_train_3), axis=1)\n",
    "data_train_total = np.concatenate((data_train_total, data_train_4), axis=1)\n",
    "\n",
    "data_val_total = np.concatenate((data_val_0, data_val_3), axis=1)\n",
    "data_val_total = np.concatenate((data_val_total, data_val_4), axis=1)\n",
    "\n",
    "data_test_total = np.concatenate((data_test[0], data_test[3]), axis=1)\n",
    "data_test_total = np.concatenate((data_test_total, data_test[4]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2450 samples, validate on 1050 samples\n",
      "Epoch 1/100\n",
      "2450/2450 [==============================] - 2s 619us/step - loss: 0.1235 - val_loss: 0.1354\n",
      "Epoch 2/100\n",
      "2450/2450 [==============================] - 1s 496us/step - loss: 0.1203 - val_loss: 0.1368\n",
      "Epoch 3/100\n",
      "2450/2450 [==============================] - 2s 614us/step - loss: 0.1203 - val_loss: 0.1350\n",
      "Epoch 4/100\n",
      "2450/2450 [==============================] - 1s 603us/step - loss: 0.1203 - val_loss: 0.1368\n",
      "Epoch 5/100\n",
      "2450/2450 [==============================] - 1s 498us/step - loss: 0.1203 - val_loss: 0.1338\n",
      "Epoch 6/100\n",
      "2450/2450 [==============================] - 1s 474us/step - loss: 0.1203 - val_loss: 0.1366\n",
      "Epoch 7/100\n",
      "2450/2450 [==============================] - 1s 498us/step - loss: 0.1203 - val_loss: 0.1348\n",
      "Epoch 8/100\n",
      "2450/2450 [==============================] - 1s 481us/step - loss: 0.1203 - val_loss: 0.1360\n",
      "Epoch 9/100\n",
      "2450/2450 [==============================] - 1s 477us/step - loss: 0.1203 - val_loss: 0.1349\n",
      "Epoch 10/100\n",
      "2450/2450 [==============================] - 1s 503us/step - loss: 0.1203 - val_loss: 0.1352\n",
      "Epoch 11/100\n",
      "2450/2450 [==============================] - 1s 491us/step - loss: 0.1203 - val_loss: 0.1354\n",
      "Epoch 12/100\n",
      "2450/2450 [==============================] - 1s 487us/step - loss: 0.1203 - val_loss: 0.1339\n",
      "Epoch 13/100\n",
      "2450/2450 [==============================] - 1s 480us/step - loss: 0.1203 - val_loss: 0.1354\n",
      "Epoch 14/100\n",
      "2450/2450 [==============================] - 1s 522us/step - loss: 0.1203 - val_loss: 0.1363\n",
      "Epoch 15/100\n",
      "2450/2450 [==============================] - 1s 475us/step - loss: 0.1203 - val_loss: 0.1338\n",
      "Epoch 16/100\n",
      "2450/2450 [==============================] - 1s 482us/step - loss: 0.1203 - val_loss: 0.1357\n",
      "Epoch 17/100\n",
      "2450/2450 [==============================] - 1s 512us/step - loss: 0.1203 - val_loss: 0.1354\n",
      "Epoch 18/100\n",
      "2450/2450 [==============================] - 1s 474us/step - loss: 0.1203 - val_loss: 0.1350\n",
      "Epoch 19/100\n",
      "2450/2450 [==============================] - 1s 472us/step - loss: 0.1202 - val_loss: 0.1364\n",
      "Epoch 20/100\n",
      "2450/2450 [==============================] - 1s 477us/step - loss: 0.1203 - val_loss: 0.1352\n",
      "Epoch 21/100\n",
      "2450/2450 [==============================] - 1s 478us/step - loss: 0.1203 - val_loss: 0.1369\n",
      "Epoch 22/100\n",
      "2450/2450 [==============================] - 1s 483us/step - loss: 0.1202 - val_loss: 0.1361\n",
      "Epoch 23/100\n",
      "2450/2450 [==============================] - 1s 476us/step - loss: 0.1203 - val_loss: 0.1351\n",
      "Epoch 24/100\n",
      "2450/2450 [==============================] - 1s 476us/step - loss: 0.1203 - val_loss: 0.1351\n",
      "Epoch 25/100\n",
      "2450/2450 [==============================] - 1s 475us/step - loss: 0.1203 - val_loss: 0.1363\n",
      "Epoch 26/100\n",
      "2450/2450 [==============================] - 1s 474us/step - loss: 0.1203 - val_loss: 0.1354\n",
      "Epoch 27/100\n",
      "2450/2450 [==============================] - 1s 478us/step - loss: 0.1203 - val_loss: 0.1344\n",
      "Epoch 28/100\n",
      "2450/2450 [==============================] - 1s 480us/step - loss: 0.1203 - val_loss: 0.1353\n",
      "Epoch 29/100\n",
      "2450/2450 [==============================] - 1s 480us/step - loss: 0.1202 - val_loss: 0.1350\n",
      "Epoch 30/100\n",
      "2450/2450 [==============================] - 1s 482us/step - loss: 0.1203 - val_loss: 0.1348\n",
      "Epoch 31/100\n",
      "2450/2450 [==============================] - 1s 477us/step - loss: 0.1202 - val_loss: 0.1353\n",
      "Epoch 32/100\n",
      "2450/2450 [==============================] - 1s 473us/step - loss: 0.1202 - val_loss: 0.1366\n",
      "Epoch 33/100\n",
      "2450/2450 [==============================] - 1s 472us/step - loss: 0.1202 - val_loss: 0.1360\n",
      "Epoch 34/100\n",
      "2450/2450 [==============================] - 1s 478us/step - loss: 0.1202 - val_loss: 0.1353\n",
      "Epoch 35/100\n",
      "2450/2450 [==============================] - 1s 467us/step - loss: 0.1202 - val_loss: 0.1344\n",
      "Epoch 36/100\n",
      "2450/2450 [==============================] - 1s 472us/step - loss: 0.1202 - val_loss: 0.1370\n",
      "Epoch 37/100\n",
      "2450/2450 [==============================] - 1s 481us/step - loss: 0.1203 - val_loss: 0.1360\n",
      "Epoch 38/100\n",
      "2450/2450 [==============================] - 1s 472us/step - loss: 0.1202 - val_loss: 0.1349\n",
      "Epoch 39/100\n",
      "2450/2450 [==============================] - 1s 483us/step - loss: 0.1202 - val_loss: 0.1352\n",
      "Epoch 40/100\n",
      "2450/2450 [==============================] - 1s 473us/step - loss: 0.1203 - val_loss: 0.1350\n",
      "Epoch 41/100\n",
      "2450/2450 [==============================] - 1s 471us/step - loss: 0.1203 - val_loss: 0.1351\n",
      "Epoch 42/100\n",
      "2450/2450 [==============================] - 1s 493us/step - loss: 0.1202 - val_loss: 0.1357\n",
      "Epoch 43/100\n",
      "2450/2450 [==============================] - 1s 476us/step - loss: 0.1203 - val_loss: 0.1358\n",
      "Epoch 44/100\n",
      "2450/2450 [==============================] - 1s 489us/step - loss: 0.1203 - val_loss: 0.1348\n",
      "Epoch 45/100\n",
      "2450/2450 [==============================] - 1s 492us/step - loss: 0.1202 - val_loss: 0.1350\n",
      "Epoch 46/100\n",
      "2450/2450 [==============================] - 1s 480us/step - loss: 0.1202 - val_loss: 0.1361\n",
      "Epoch 47/100\n",
      "2450/2450 [==============================] - 1s 480us/step - loss: 0.1202 - val_loss: 0.1343\n",
      "Epoch 48/100\n",
      "2450/2450 [==============================] - 1s 480us/step - loss: 0.1202 - val_loss: 0.1343\n",
      "Epoch 49/100\n",
      "2450/2450 [==============================] - 1s 476us/step - loss: 0.1203 - val_loss: 0.1352\n",
      "Epoch 50/100\n",
      "2450/2450 [==============================] - 1s 481us/step - loss: 0.1202 - val_loss: 0.1360\n",
      "Epoch 51/100\n",
      "2450/2450 [==============================] - 1s 518us/step - loss: 0.1202 - val_loss: 0.1344\n",
      "Epoch 52/100\n",
      "2450/2450 [==============================] - 1s 485us/step - loss: 0.1202 - val_loss: 0.1370\n",
      "Epoch 53/100\n",
      "2450/2450 [==============================] - 1s 484us/step - loss: 0.1203 - val_loss: 0.1349\n",
      "Epoch 54/100\n",
      "2450/2450 [==============================] - 1s 479us/step - loss: 0.1202 - val_loss: 0.1360\n",
      "Epoch 55/100\n",
      "2450/2450 [==============================] - 1s 480us/step - loss: 0.1202 - val_loss: 0.1346\n",
      "Epoch 56/100\n",
      "2450/2450 [==============================] - 1s 478us/step - loss: 0.1203 - val_loss: 0.1358\n",
      "Epoch 57/100\n",
      "2450/2450 [==============================] - 1s 480us/step - loss: 0.1203 - val_loss: 0.1355\n",
      "Epoch 58/100\n",
      "2450/2450 [==============================] - 1s 480us/step - loss: 0.1202 - val_loss: 0.1360\n",
      "Epoch 59/100\n",
      "2450/2450 [==============================] - 1s 481us/step - loss: 0.1202 - val_loss: 0.1342\n",
      "Epoch 60/100\n",
      "2450/2450 [==============================] - 1s 482us/step - loss: 0.1203 - val_loss: 0.1366\n",
      "Epoch 61/100\n",
      "2450/2450 [==============================] - 1s 477us/step - loss: 0.1202 - val_loss: 0.1340\n",
      "Epoch 62/100\n",
      "2450/2450 [==============================] - 1s 481us/step - loss: 0.1202 - val_loss: 0.1353\n",
      "Epoch 63/100\n",
      "2450/2450 [==============================] - 1s 482us/step - loss: 0.1202 - val_loss: 0.1356\n",
      "Epoch 64/100\n",
      "2450/2450 [==============================] - 1s 476us/step - loss: 0.1202 - val_loss: 0.1338\n",
      "Epoch 65/100\n",
      "2450/2450 [==============================] - 1s 482us/step - loss: 0.1203 - val_loss: 0.1349\n",
      "Epoch 66/100\n",
      "2450/2450 [==============================] - 1s 482us/step - loss: 0.1202 - val_loss: 0.1343\n",
      "Epoch 67/100\n",
      "2450/2450 [==============================] - 1s 477us/step - loss: 0.1202 - val_loss: 0.1353\n",
      "Epoch 68/100\n",
      "2450/2450 [==============================] - 1s 478us/step - loss: 0.1203 - val_loss: 0.1345\n",
      "Epoch 69/100\n",
      "2450/2450 [==============================] - 1s 478us/step - loss: 0.1202 - val_loss: 0.1359\n",
      "Epoch 70/100\n",
      "2450/2450 [==============================] - 1s 484us/step - loss: 0.1202 - val_loss: 0.1359\n",
      "Epoch 71/100\n",
      "2450/2450 [==============================] - 1s 469us/step - loss: 0.1202 - val_loss: 0.1364\n",
      "Epoch 72/100\n",
      "2450/2450 [==============================] - 1s 484us/step - loss: 0.1203 - val_loss: 0.1351\n",
      "Epoch 73/100\n",
      "2450/2450 [==============================] - 1s 478us/step - loss: 0.1202 - val_loss: 0.1374\n",
      "Epoch 74/100\n",
      "2450/2450 [==============================] - 1s 481us/step - loss: 0.1202 - val_loss: 0.1354\n",
      "Epoch 75/100\n",
      "2450/2450 [==============================] - 1s 477us/step - loss: 0.1202 - val_loss: 0.1364\n",
      "Epoch 76/100\n",
      "2450/2450 [==============================] - 1s 482us/step - loss: 0.1202 - val_loss: 0.1348\n",
      "Epoch 77/100\n",
      "2450/2450 [==============================] - 1s 482us/step - loss: 0.1202 - val_loss: 0.1364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "2450/2450 [==============================] - 1s 473us/step - loss: 0.1202 - val_loss: 0.1357\n",
      "Epoch 79/100\n",
      "2450/2450 [==============================] - 1s 478us/step - loss: 0.1202 - val_loss: 0.1369\n",
      "Epoch 80/100\n",
      "2450/2450 [==============================] - 1s 472us/step - loss: 0.1202 - val_loss: 0.1366\n",
      "Epoch 81/100\n",
      "2450/2450 [==============================] - 1s 477us/step - loss: 0.1202 - val_loss: 0.1342\n",
      "Epoch 82/100\n",
      "2450/2450 [==============================] - 1s 469us/step - loss: 0.1203 - val_loss: 0.1354\n",
      "Epoch 83/100\n",
      "2450/2450 [==============================] - 1s 473us/step - loss: 0.1202 - val_loss: 0.1353\n",
      "Epoch 84/100\n",
      "2450/2450 [==============================] - 1s 469us/step - loss: 0.1202 - val_loss: 0.1356\n",
      "Epoch 85/100\n",
      "2450/2450 [==============================] - 1s 475us/step - loss: 0.1202 - val_loss: 0.1358\n",
      "Epoch 86/100\n",
      "2450/2450 [==============================] - 1s 474us/step - loss: 0.1202 - val_loss: 0.1359\n",
      "Epoch 87/100\n",
      "2450/2450 [==============================] - 1s 472us/step - loss: 0.1202 - val_loss: 0.1349\n",
      "Epoch 88/100\n",
      "2450/2450 [==============================] - 1s 471us/step - loss: 0.1202 - val_loss: 0.1351\n",
      "Epoch 89/100\n",
      "2450/2450 [==============================] - 1s 473us/step - loss: 0.1202 - val_loss: 0.1359\n",
      "Epoch 90/100\n",
      "2450/2450 [==============================] - 1s 470us/step - loss: 0.1202 - val_loss: 0.1372\n",
      "Epoch 91/100\n",
      "2450/2450 [==============================] - 1s 471us/step - loss: 0.1202 - val_loss: 0.1350\n",
      "Epoch 92/100\n",
      "2450/2450 [==============================] - 1s 468us/step - loss: 0.1202 - val_loss: 0.1346\n",
      "Epoch 93/100\n",
      "2450/2450 [==============================] - 1s 472us/step - loss: 0.1202 - val_loss: 0.1355\n",
      "Epoch 94/100\n",
      "2450/2450 [==============================] - 1s 474us/step - loss: 0.1202 - val_loss: 0.1371\n",
      "Epoch 95/100\n",
      "2450/2450 [==============================] - 1s 470us/step - loss: 0.1202 - val_loss: 0.1348\n",
      "Epoch 96/100\n",
      "2450/2450 [==============================] - 1s 467us/step - loss: 0.1202 - val_loss: 0.1354\n",
      "Epoch 97/100\n",
      "2450/2450 [==============================] - 1s 473us/step - loss: 0.1202 - val_loss: 0.1344\n",
      "Epoch 98/100\n",
      "2450/2450 [==============================] - 1s 474us/step - loss: 0.1202 - val_loss: 0.1350\n",
      "Epoch 99/100\n",
      "2450/2450 [==============================] - 1s 477us/step - loss: 0.1202 - val_loss: 0.1345\n",
      "Epoch 100/100\n",
      "2450/2450 [==============================] - 1s 471us/step - loss: 0.1202 - val_loss: 0.1361\n",
      "1050/1050 [==============================] - 0s 100us/step\n",
      "0.12495067159334819\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=data_train_total.shape[1], kernel_initializer='uniform',activation=\"softsign\"))\n",
    "model.add(Dense(512, input_dim=data_train_total.shape[1], kernel_initializer='uniform',activation=\"linear\"))\n",
    "model.add(Dense(256, input_dim=data_train_total.shape[1], kernel_initializer='uniform',activation=\"softsign\"))\n",
    "model.add(Dense(128, input_dim=data_train_total.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(64, input_dim=data_train_total.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(7, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.01),loss='mean_squared_error')\n",
    "fit = model.fit(data_train_total, data_train_1, epochs=100, verbose=1, validation_data=(data_val_total, data_val_1))\n",
    "\n",
    "evalu = model.evaluate(x=data_test_total, y=data_test[1])\n",
    "\n",
    "print(evalu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
